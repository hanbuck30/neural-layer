{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUNqInupU5XbPiqYSb1Kek",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hanbuck30/neural-layer/blob/main/RNN_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {
        "id": "URCoh7ZY4l0G"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "timesteps = 5 # 시점의 수. NLP에서는 보통 문장의 길이\n",
        "input_size = 3 # 입력의 차원. NLP에서는 보통 단어 벡터의 차원\n",
        "hidden_size = 8 # 은닉 상태의 크기. 메모리 셀의 용량\n",
        "output_size=5\n",
        "batch_size=1\n",
        "inputs = torch.randn(batch_size,timesteps,input_size)\n",
        "hidden_state_t=torch.zeros(hidden_size,requires_grad=True)\n"
      ],
      "metadata": {
        "id": "CTkE6oG449h9"
      },
      "execution_count": 298,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Wx = torch.randn(hidden_size, input_size,requires_grad=True) \n",
        "Wh = torch.randn(hidden_size, hidden_size,requires_grad=True)\n",
        "b = torch.randn(hidden_size,requires_grad=True)\n",
        "learning_rate = 0.1"
      ],
      "metadata": {
        "id": "jQ5UYob-61bi"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(Wx.shape)\n",
        "print(Wh.shape)\n",
        "print(b.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0vcWbbQ7XW2",
        "outputId": "f7b483c6-7d6d-41ac-ed9e-f926e6f32a42"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([8, 3])\n",
            "torch.Size([8, 8])\n",
            "torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJB-9u6W3aOJ",
        "outputId": "3ce97ff7-8764-40e9-9c13-2c8441bedffe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y=torch.LongTensor([[0,1,2,3,4]])\n",
        "y_data=[Y]\n",
        "Y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srZJhB-ck4ev",
        "outputId": "2500e18c-0991-4c11-917a-da4a62a02781"
      },
      "execution_count": 245,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 245
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b_fc=torch.randn(output_size,requires_grad=True)\n",
        "w_fc=torch.randn(hidden_size, output_size,requires_grad=True)"
      ],
      "metadata": {
        "id": "y5usjXzofPhm"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RNNModel(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self,input_size,hidden_size,output_size,num_layers):\n",
        "        super(RNNModel,self).__init__()\n",
        "        self.input_size=input_size\n",
        "        self.hidden_size=hidden_size\n",
        "        self.num_layers=num_layers\n",
        "        self.output_size = output_size\n",
        "        self.Wx = torch.randn(hidden_size, input_size,requires_grad=True) \n",
        "        self.Wh = torch.randn(hidden_size, hidden_size,requires_grad=True)\n",
        "        self.b = torch.randn(hidden_size,requires_grad=True)\n",
        "        self.parameters=[]\n",
        "        \n",
        "        self.b_fc=torch.randn(output_size,requires_grad=True)\n",
        "        self.w_fc=torch.randn(hidden_size, output_size,requires_grad=True)\n",
        "        if num_layers >= 2:\n",
        "            for k in range(1,num_layers):\n",
        "                globals()['W{}'.format(k)]=torch.randn(hidden_size,hidden_size,requires_grad=True)\n",
        "                globals()['b{}'.format(k)]=torch.randn(hidden_size,requires_grad=True)\n",
        "                globals()['Wh{}'.format(k)]=torch.randn(hidden_size,hidden_size,requires_grad=True)\n",
        "                globals()['hidden_state_t{}'.format(k)]=torch.zeros(hidden_size,requires_grad=True)\n",
        "    \n",
        "    def make_parameters(self,num_layers):\n",
        "        global parameters\n",
        "        parameters=[Wx,Wh,b,b_fc,w_fc]\n",
        "        for k in range(1,num_layers):\n",
        "                parameters.append(globals()['W{}'.format(k)])\n",
        "                parameters.append(globals()['b{}'.format(k)])\n",
        "                parameters.append(globals()['Wh{}'.format(k)])\n",
        "                parameters.append(globals()['hidden_state_t{}'.format(k)]) \n",
        "           \n",
        "    def rnn(self,inputs):\n",
        "        hidden_state_t=torch.zeros(hidden_size,requires_grad=True)\n",
        "        total_hidden_state=[]\n",
        "        total_hidden_states=[]\n",
        "        if self.num_layers ==1:\n",
        "            for i in inputs:\n",
        "                for input_t in i: \n",
        "                    output_t = torch.tanh(torch.matmul(Wx,input_t) + torch.matmul(Wh,hidden_state_t) + b)\n",
        "                    total_hidden_states.append(output_t) \n",
        "                    hidden_state_t = output_t\n",
        "                total_state = torch.stack(total_hidden_states,dim=0)\n",
        "                total_hidden_state.append(total_state)\n",
        "            total_state=torch.stack(total_hidden_state,dim=0)\n",
        "            return total_state\n",
        "        elif self.num_layers == 2: \n",
        "            for i in inputs:\n",
        "                for input_t in i: \n",
        "                    output_t = torch.tanh(torch.matmul(Wx,input_t) + torch.matmul(Wh,hidden_state_t) + b)\n",
        "                    hidden_state_t = output_t\n",
        "                    output_t1 = torch.tanh(torch.matmul(W1,hidden_state_t) + torch.matmul(Wh1,hidden_state_t1) + b1)\n",
        "                    hiddent_state_t1=output_t1\n",
        "                    total_hidden_states.append(output_t1)\n",
        "                total_state = torch.stack(total_hidden_states,dim=0)\n",
        "                total_hidden_state.append(total_state)\n",
        "            total_state=torch.stack(total_hidden_state,dim=0)\n",
        "            return total_state\n",
        "        elif self.num_layers > 2:\n",
        "            for i in inputs:\n",
        "                for input_t in i: \n",
        "                    output_t = torch.tanh(torch.matmul(Wx,input_t) + torch.matmul(Wh,hidden_state_t) + b)\n",
        "                    hidden_state_t = output_t\n",
        "                    output_t1 = torch.tanh(torch.matmul(W1,hidden_state_t) + torch.matmul(Wh1,hidden_state_t1) + b1)\n",
        "                    hiddent_state_t1=output_t1\n",
        "                    for m in range(2,num_layers):\n",
        "                        globals()['output_t{}'.format(m)] = torch.tanh(torch.matmul(globals()['W{}'.format(m)],globals()['hidden_state_t{}'.format(m)]) + torch.matmul(globals()['Wh{}'.format(m)],globals()['hidden_state_t{}'.format(m-1)]) + globals()['b{}'.format(m)])\n",
        "                        globals()['hidden_state_t{}'.format(m)] = globals()['output_t{}'.format(m)]\n",
        "                    total_hidden_states.append(globals()['output_t{}'.format(num_layers)])\n",
        "                total_state = torch.stack(total_hidden_states,dim=0)\n",
        "                total_hidden_state.append(total_state)\n",
        "            total_state=torch.stack(total_hidden_state,dim=0)\n",
        "            return total_state\n",
        "    def fc(self,total_state):\n",
        "        linear=torch.matmul(total_state,w_fc)+b_fc\n",
        "        return linear\n",
        "    def forward(self,inputs):\n",
        "        x=self.rnn(inputs)\n",
        "        v=self.fc(x)\n",
        "        return v\n",
        "    \n"
      ],
      "metadata": {
        "id": "Olq3SeVHWIJ4"
      },
      "execution_count": 302,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=RNNModel(input_size, hidden_size, output_size, 4)\n",
        "model.make_parameters(4)\n",
        "print(len(parameters))\n",
        "net=model(inputs)\n",
        "net"
      ],
      "metadata": {
        "id": "t1qF3-f_dpNh",
        "outputId": "df7160af-d170-42ef-fd90-edc77e5a988b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 303,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.1897, -2.8213,  4.8691,  3.8571,  2.0977],\n",
              "         [-1.1897, -2.8213,  4.8691,  3.8571,  2.0977],\n",
              "         [-1.1897, -2.8213,  4.8691,  3.8571,  2.0977],\n",
              "         [-1.1897, -2.8213,  4.8691,  3.8571,  2.0977],\n",
              "         [-1.1897, -2.8213,  4.8691,  3.8571,  2.0977]]],\n",
              "       grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 303
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def RNNmodel(inputs,hidden_state_t,num_layers):\n",
        "    total_hidden_state=[]\n",
        "    total_hidden_states=[]\n",
        "    def RNN(inputs,hidden_state_t,num_layers):\n",
        "        for i in inputs:\n",
        "            for input_t in i: \n",
        "                output_t = torch.tanh(torch.matmul(Wx,input_t) + torch.matmul(Wh,hidden_state_t) + b)\n",
        "                total_hidden_states.append(output_t) \n",
        "                hidden_state_t = output_t\n",
        "            total_state = torch.stack(total_hidden_states,dim=0)\n",
        "            total_hidden_state.append(total_state)\n",
        "        total_state=torch.stack(total_hidden_state,dim=0)\n",
        "        return total_state\n",
        "    def RNN_two(inputs,hidden_state_t,num_layers):\n",
        "        for k in range(1,num_layers):\n",
        "            globals()['W{}'.format(k)]=torch.randn(hidden_size,hidden_size,requires_grad=True)\n",
        "            globals()['b{}'.format(k)]=torch.randn(hidden_size,requires_grad=True)\n",
        "            globals()['Wh{}'.format(k)]=torch.randn(hidden_size,hidden_size,requires_grad=True)\n",
        "            globals()['hidden_state_t{}'.format(k)]=torch.zeros(hidden_size,requires_grad=True)\n",
        "        for i in inputs:\n",
        "            for input_t in i: \n",
        "                output_t = torch.tanh(torch.matmul(Wx,input_t) + torch.matmul(Wh,hidden_state_t) + b)\n",
        "                hidden_state_t = output_t\n",
        "                output_t1 = torch.tanh(torch.matmul(W1,hidden_state_t) + torch.matmul(Wh1,hidden_state_t1) + b1)\n",
        "                hiddent_state_t1=output_t1\n",
        "                total_hidden_states.append(output_t1)\n",
        "            total_state = torch.stack(total_hidden_states,dim=0)\n",
        "            total_hidden_state.append(total_state)\n",
        "        total_state=torch.stack(total_hidden_state,dim=0)\n",
        "        return total_state\n",
        "    def RNN_multi(inputs,hidden_state_t,num_layers):\n",
        "        for k in range(1,num_layers):\n",
        "            globals()['W{}'.format(k)]=torch.randn(hidden_size,hidden_size,requires_grad=True)\n",
        "            globals()['b{}'.format(k)]=torch.randn(hidden_size,requires_grad=True)\n",
        "            globals()['Wh{}'.format(k)]=torch.randn(hidden_size,hidden_size,requires_grad=True)\n",
        "            globals()['hidden_state_t{}'.format(k)]=torch.zeros(hidden_size,requires_grad=True)\n",
        "        for i in inputs:\n",
        "            for input_t in i: \n",
        "                output_t = torch.tanh(torch.matmul(Wx,input_t) + torch.matmul(Wh,hidden_state_t) + b)\n",
        "                hidden_state_t = output_t\n",
        "                output_t1 = torch.tanh(torch.matmul(W1,hidden_state_t) + torch.matmul(Wh1,hidden_state_t1) + b1)\n",
        "                hiddent_state_t1=output_t1\n",
        "                for m in range(2,num_layers):\n",
        "                    globals()['output_t{}'.format(m)] = torch.tanh(torch.matmul(globals()['W{}'.format(m)],globals()['hidden_state_t{}'.format(m)]) + torch.matmul(globals()['Wh{}'.format(m)],globals()['hidden_state_t{}'.format(m-1)]) + globals()['b{}'.format(m)])\n",
        "                    globals()['hidden_state_t{}'.format(m)] = globals()['output_t{}'.format(m)]\n",
        "                total_hidden_states.append(globals()['output_t{}'.format(num_layers-1)])\n",
        "            total_state = torch.stack(total_hidden_states,dim=0)\n",
        "            total_hidden_state.append(total_state)\n",
        "        total_state=torch.stack(total_hidden_state,dim=0)\n",
        "        return total_state\n",
        "    def fc(total_state):\n",
        "        linear=torch.matmul(total_state,w_fc)+b_fc\n",
        "        return linear\n",
        "    if num_layers == 1:\n",
        "        v=fc(RNN(inputs,hidden_state_t,num_layers))\n",
        "        return v\n",
        "    elif num_layers== 2 :\n",
        "        v=fc(RNN_two(inputs,hidden_state_t,num_layers))\n",
        "        return v\n",
        "    else:\n",
        "        v=fc(RNN_multi(inputs,hidden_state_t,num_layers))\n",
        "        return v\n",
        "RNNmodel(inputs,hidden_state_t,2).shape\n",
        "#RNNmodel(inputs,hidden_state_t,2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QerjedRRi4in",
        "outputId": "94b05716-4889-438a-c2cb-d11936d93d37"
      },
      "execution_count": 280,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 5, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 280
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parameters=[Wx,Wh,b,b_fc,w_fc]\n",
        "def make_parameters(num_layers):\n",
        "    for k in range(1,num_layers):\n",
        "            parameters.append(globals()['W{}'.format(k)])\n",
        "            parameters.append(globals()['b{}'.format(k)])\n",
        "            parameters.append(globals()['Wh{}'.format(k)])\n",
        "            parameters.append(globals()['hidden_state_t{}'.format(k)])\n",
        "make_parameters(num_layers)\n"
      ],
      "metadata": {
        "id": "3135wH32VtYO"
      },
      "execution_count": 296,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(parameters)"
      ],
      "metadata": {
        "id": "o8-oGGlcMNMi",
        "outputId": "11baed27-d759-43e5-a604-3cd316315257",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 297,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {},
          "execution_count": 297
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(parameters, learning_rate)"
      ],
      "metadata": {
        "id": "MAaEYC05duwo",
        "outputId": "5287399e-33ea-461a-9031-b4cc535385ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 243,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/optim/adam.py:137: UserWarning: optimizer contains a parameter group with duplicate parameters; in future, this will cause an error; see github.com/pytorch/pytorch/issues/40967 for more information\n",
            "  super(Adam, self).__init__(params, defaults)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(100):\n",
        "    total_hidden_state=[]\n",
        "    total_hidden_states=[]\n",
        "    optimizer.zero_grad()\n",
        "    outputs=RNNmodel(inputs,hidden_state_t,num_layers)\n",
        "    loss = criterion(outputs.view(-1,output_size), Y.view(-1)) # view를 하는 이유는 Batch 차원 제거를 위해\n",
        "    loss.backward() \n",
        "    optimizer.step() \n",
        "\n",
        "    \n",
        "    result = outputs.data.numpy().argmax(axis=2) \n",
        "    print(i, \"loss: \", loss.item(), \"prediction: \", result, \"true Y: \", y_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wrk95TAAjpKE",
        "outputId": "e46de2e9-02ae-4fae-f106-10b7af19cd45"
      },
      "execution_count": 304,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 loss:  2.672586441040039 prediction:  [[2 2 2 2 3]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "1 loss:  3.308218002319336 prediction:  [[1 0 0 4 0]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "2 loss:  4.615926265716553 prediction:  [[2 4 2 2 2]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "3 loss:  3.349600315093994 prediction:  [[3 0 1 0 2]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "4 loss:  3.8808753490448 prediction:  [[2 3 2 3 2]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "5 loss:  3.707132339477539 prediction:  [[4 0 2 0 2]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "6 loss:  3.9745421409606934 prediction:  [[2 2 3 2 2]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "7 loss:  5.564478874206543 prediction:  [[1 2 1 1 0]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "8 loss:  3.197936534881592 prediction:  [[0 1 1 3 1]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "9 loss:  3.5745692253112793 prediction:  [[2 1 2 1 3]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "10 loss:  2.982217311859131 prediction:  [[1 3 1 3 1]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "11 loss:  2.1584908962249756 prediction:  [[2 1 2 1 2]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "12 loss:  3.2630603313446045 prediction:  [[4 2 4 2 4]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "13 loss:  1.5585427284240723 prediction:  [[0 3 2 4 3]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "14 loss:  3.5933563709259033 prediction:  [[4 4 2 4 4]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "15 loss:  3.576035261154175 prediction:  [[4 2 4 2 2]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "16 loss:  2.027413845062256 prediction:  [[1 4 2 4 2]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "17 loss:  3.6470298767089844 prediction:  [[4 2 4 2 4]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "18 loss:  1.4414955377578735 prediction:  [[2 3 2 3 4]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "19 loss:  3.351170063018799 prediction:  [[4 2 4 2 1]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "20 loss:  2.261979579925537 prediction:  [[3 4 3 3 0]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "21 loss:  3.562678098678589 prediction:  [[1 3 1 3 1]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "22 loss:  2.736616611480713 prediction:  [[4 4 3 3 3]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "23 loss:  2.0922818183898926 prediction:  [[3 1 4 1 4]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "24 loss:  3.2991230487823486 prediction:  [[1 2 3 2 3]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "25 loss:  1.610603928565979 prediction:  [[2 1 2 1 2]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "26 loss:  2.5171103477478027 prediction:  [[3 4 3 3 3]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "27 loss:  2.0424365997314453 prediction:  [[3 4 3 4 3]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "28 loss:  1.723737359046936 prediction:  [[2 3 3 3 3]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "29 loss:  1.9635330438613892 prediction:  [[4 4 4 3 4]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "30 loss:  2.378373622894287 prediction:  [[1 1 1 1 1]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "31 loss:  2.2243196964263916 prediction:  [[2 4 3 4 3]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "32 loss:  1.976458191871643 prediction:  [[4 0 4 0 4]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "33 loss:  2.244544506072998 prediction:  [[4 0 4 2 4]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "34 loss:  2.023453950881958 prediction:  [[3 4 3 4 3]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "35 loss:  2.2693066596984863 prediction:  [[3 1 1 1 1]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "36 loss:  1.2778167724609375 prediction:  [[0 1 4 1 4]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "37 loss:  2.3731837272644043 prediction:  [[1 2 4 2 4]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "38 loss:  1.581735372543335 prediction:  [[0 4 0 3 0]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "39 loss:  2.347175359725952 prediction:  [[0 4 0 4 0]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "40 loss:  1.5792841911315918 prediction:  [[3 0 2 0 2]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "41 loss:  1.6965892314910889 prediction:  [[0 4 0 4 0]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "42 loss:  1.7795947790145874 prediction:  [[3 1 3 1 3]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "43 loss:  2.0811445713043213 prediction:  [[3 2 3 2 3]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "44 loss:  1.6220697164535522 prediction:  [[1 1 1 1 1]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "45 loss:  1.1098896265029907 prediction:  [[0 3 0 3 0]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "46 loss:  1.4663636684417725 prediction:  [[0 1 0 1 0]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "47 loss:  1.4965589046478271 prediction:  [[4 3 4 3 4]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "48 loss:  1.4669580459594727 prediction:  [[1 3 2 3 2]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "49 loss:  2.0481221675872803 prediction:  [[4 0 4 0 4]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "50 loss:  1.5171103477478027 prediction:  [[1 1 2 1 2]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "51 loss:  2.091386556625366 prediction:  [[1 1 1 1 1]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "52 loss:  1.6774991750717163 prediction:  [[2 0 2 0 2]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "53 loss:  1.2453948259353638 prediction:  [[2 1 2 1 2]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "54 loss:  1.907086730003357 prediction:  [[4 0 1 0 1]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "55 loss:  1.3844231367111206 prediction:  [[2 1 2 1 2]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "56 loss:  1.5609986782073975 prediction:  [[0 1 0 1 0]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "57 loss:  1.8144031763076782 prediction:  [[1 4 2 4 2]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "58 loss:  2.0978972911834717 prediction:  [[1 0 1 0 1]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "59 loss:  1.6953519582748413 prediction:  [[3 2 4 2 4]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "60 loss:  2.208042621612549 prediction:  [[1 4 1 4 1]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "61 loss:  2.2314484119415283 prediction:  [[4 4 4 4 4]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "62 loss:  1.3484097719192505 prediction:  [[4 1 2 1 2]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "63 loss:  2.6068739891052246 prediction:  [[3 2 1 2 1]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "64 loss:  1.865928053855896 prediction:  [[4 2 4 2 4]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "65 loss:  1.2665332555770874 prediction:  [[2 3 2 3 2]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "66 loss:  1.5171468257904053 prediction:  [[0 3 0 3 0]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "67 loss:  2.8307902812957764 prediction:  [[0 4 3 4 3]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "68 loss:  2.019002676010132 prediction:  [[0 0 3 0 3]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "69 loss:  1.8381754159927368 prediction:  [[3 4 2 4 2]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "70 loss:  1.4419126510620117 prediction:  [[2 1 2 1 2]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "71 loss:  1.880194067955017 prediction:  [[0 4 0 4 0]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "72 loss:  1.9558464288711548 prediction:  [[3 0 1 0 1]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "73 loss:  1.9060341119766235 prediction:  [[3 1 3 1 3]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "74 loss:  2.008366823196411 prediction:  [[2 0 3 0 3]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "75 loss:  2.678332805633545 prediction:  [[3 2 3 2 3]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "76 loss:  1.353302240371704 prediction:  [[1 0 2 0 2]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "77 loss:  1.8770071268081665 prediction:  [[1 4 0 4 0]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "78 loss:  1.5156207084655762 prediction:  [[1 4 2 4 2]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "79 loss:  2.125248432159424 prediction:  [[0 4 3 4 3]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "80 loss:  1.2944213151931763 prediction:  [[2 3 2 3 2]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "81 loss:  1.5256843566894531 prediction:  [[0 3 0 3 0]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "82 loss:  2.1424105167388916 prediction:  [[0 2 3 2 3]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "83 loss:  1.368028998374939 prediction:  [[4 3 4 3 4]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "84 loss:  2.0164828300476074 prediction:  [[1 2 1 2 1]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "85 loss:  1.5129668712615967 prediction:  [[0 2 0 2 0]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "86 loss:  1.3628705739974976 prediction:  [[4 3 4 3 4]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "87 loss:  1.3259557485580444 prediction:  [[4 3 4 3 4]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "88 loss:  1.399114727973938 prediction:  [[0 4 0 4 0]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "89 loss:  1.9786990880966187 prediction:  [[3 0 3 0 3]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "90 loss:  1.4013303518295288 prediction:  [[4 3 4 3 4]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "91 loss:  2.0394625663757324 prediction:  [[0 4 3 4 3]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "92 loss:  2.528059720993042 prediction:  [[1 0 1 0 1]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "93 loss:  2.175158739089966 prediction:  [[3 0 3 0 3]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "94 loss:  1.825385332107544 prediction:  [[1 0 4 0 4]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "95 loss:  1.1069421768188477 prediction:  [[4 1 4 1 4]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "96 loss:  1.699733018875122 prediction:  [[2 0 2 0 2]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "97 loss:  1.7423114776611328 prediction:  [[3 3 4 3 4]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "98 loss:  1.7360382080078125 prediction:  [[4 2 2 2 2]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n",
            "99 loss:  2.2249438762664795 prediction:  [[3 2 3 2 3]] true Y:  [tensor([[0, 1, 2, 3, 4]])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h7uZIRBAaJdY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}